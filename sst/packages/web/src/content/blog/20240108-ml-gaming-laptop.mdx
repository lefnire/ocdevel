export const id = '20240108-ml-gaming-laptop'
export const date = '2024-01-08'
export const updated = '2025-02-06'
export const title = "Laptop for machine learning and gaming"
export const teaser = "My recommended laptop for anyone who games, or who works in machine learning / AI, or both. I'll modify this post any time one contender becomes more compelling than another."

I strongly recommend the [Legion Pro series](https://www.lenovo.com/us/en/c/laptops/legion-laptops/legion-pro-series). Check [gaminglaptop.deals](https://gaminglaptop.deals/) against [brand quality](https://www.reddit.com/r/GamingLaptops/comments/1hbvrvo/this_is_how_often_a_product_of_this_brand_in_the/). Current favorite deal: [Legion 7i 2024 $2449](https://www.bhphotovideo.com/c/product/1811267-REG/lenovo_83de0008us_16_legion_pro_7.html) (as of 2025-02-06, may change before I update). Also get this [cooling pad](https://amzn.to/40qoh6s) to control temps (which impacts performance) and protect from dust.

### Only Gaming
If you're buying it *only* for gaming, get as high a GPU as you can afford in the Nvidia 40-series, anything 4070 and above. The 50-series raster gains are marginal (low bang-for-buck). And DLSS4 (the main performance marketing of the 50-series launch) is backwards-compatible to 40. This offers AI upscaling and multi-frame generation, which improve gaming performance significantly. It opens performance improvements to software instead of hardware, so your laptop can continue to improve as Nvidia drivers release. You'll be limited in DLSS capabilities if you buy a 30-series Nvidia; so if you plan to game, get a 4070+. I recommend a 4080. Nvidia is recommended over AMD due to DLSS.

### Gaming & ML Programming
If you're buying the laptop for ML training *and* gaming, get 4090. With ML, VRAM is more essential than compute, and the top tier of each series (xx90) has the highest VRAM. Nvidia is required - ML frameworks are Nvidia-first, through CUDA and CuDNN.

### Only ML Programming
If you're buying the laptop *only* for work in ML, you can downgrade to 3090 and save lots of money. Much cheaper than 40/50-series, but in the VRAM sweet-spot at an xx90. Use WSL2 (Ubuntu) + Docker for your ML work, see [mla/12](/mlg/mla-12) for details.

---

Why not Mac? For gamers it's obvious. But for ML, while strides are being taken in Apple Silicon (eg with LLMs), it's still not first-class. If you plan to do heavy ML work, you're much safer with a PC.