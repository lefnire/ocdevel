[00:00:00] February 9th, 2017. this is episode two. What is artificial intelligence and machine learning. In this episode, we're going to define artificial intelligence. We're going to compare it to machine learning, data science and statistics. And we're going to go into a very brief history of the field.

[00:00:18] So what is artificial intelligence? All this stuff is coming from Wikipedia. So, and I highly recommend just reading the Wikipedia article. It has, the history has a lot of the definition and goals and sub fields and stuff like this. The definition is. To simulate any intellectual task. Okay. Artificial intelligence is simulating any intellectual task.

[00:00:40] And it's a very loaded statement, it means you can do anything. Mental, anything. Mental is artificial intelligence. This is kind of like the goal of the industrial revolution, which is basically to simulate the body through robotics in order, you know, in factory settings, in order to build cars and machinery and all this.

[00:00:58] Well, we're doing the only other thing left in the human, which is to simulate the brain, simulate any intellectual task. We'll come back to this definition and kind of, piece it apart and talk about why there's a lot of importance in what's being said later, but let's start now with, what are the goals of artificial intelligence?

[00:01:14] So there's, sub-fields in artificial intelligence. Artificial intelligence, you imagine it like a circle and inside of it are sub circles. So one is search and. Okay. An example of this is playing chess. So the act of playing chess in AI, you're searching through a bunch of possible actions that you can take and you plan a response to an opponent's move, searching and planning.

[00:01:38] Another sub field is reasoning and knowledge representation. An example of this is when, IBM Watson. Jeopardy played the world champion at jeopardy. When a question is asked by the moderator of jeopardy, then IBM Watson has to go into, I mean, it can scrape the web for all the answers out there, but it has to do so in a way that it stores the information gained from the web.

[00:02:02] It stores that information in a representative way that it can reason about and jump to conclusions, make analogies from point a to point B and come up with a proper response. So that's reasoning and knowledge representation. Another piece is perception. So vision touch hearing. Another piece is the ability to move and manipulate objects.

[00:02:22] So this is a what's called actuators. It's basically a sub-component of robotics and robotics bleeds into artificial intelligence. Of course, you have to have a body. So, move and manipulate objects and finally natural language processing or communication, NLP. And of course, there's one more circle, which I'm going to get to in a minute, but just a brief recap, searching and planning, reasoning, and knowledge, representation, perception, the ability to move and manipulate objects, natural language processing.

[00:02:53] These are all sub fields of artificial intelligence. And the final subfield is learning. So this whole podcast is intended to teach you machine learning, this specific subfield of artificial intelligence. Now you may be wondering why would I teach you such a small subset of such a broad field? Why wouldn't I just teach you artificial intelligence?

[00:03:21] Well, there's a big reason for this. It turns out that machine learning may in fact be sort of the, the essential component of artificial intelligence machine learning is being applied to all of the sub-fields of AI. So while all the other stuff feels, you make, think of them as. Inside the greater circle of AI and maybe they bleed into each other.

[00:03:46] There are circles that have some overlap with each other here and there. Well, machine learning is more of like a splotch, a giant splotch with tendrils that reaches its tentacles into these other circles. And more and more is subsuming these other sub-fields. So we'll talk a little bit more about that later, but more and more in the modern era machine learning is kind of the more fundamental component of artificial intelligence.

[00:04:15] Okay. Let's talk about applications of artificial intelligence. Again, any intellectual task you can simulate is an application of artificial intelligence. So autonomous vehicles like drones and self-driving cars, those of course incorporate robotics, but they are primarily driven by the driver, you know, in the mind of the machine medical diagnoses,

[00:04:37] creating arts. So this is an interesting thing that we'll get back into in a future podcast episode, talking about creativity in artificial intelligence and can in fact, AI be creative. Are humans actually creative at all? Proving mathematical theorems playing games, such as chess or go like I'd mentioned previously search engines.

[00:04:58] Google of course. Online assistants such as Siri, image recognition, spam filtering prediction of judicial decisions. This is a very interesting one that's come up recently is, basically an AI judge, just going through millions of prior court decisions based on evidence using those as an example to learn from.

[00:05:20] future predictions based on current evidence and target targeting online, advertising all these things. Now, one interesting thing is that what is AI tends to be kind of a fuzzy definition? when a technique goes mainstream, such as, autonomous vehicles now is kind of like, we know that autonomous vehicles are on the horizon.

[00:05:41] In fact, autonomous vehicles Are already in a lot of cities already. And so people are starting already to consider that not AI. We call this the AI effect. It's when something goes mainstream, what was previously considered? Definitely AI is now mainstream and people no longer consider AI as a result.

[00:06:03] It's called AI effect. And this has happened since the Dawn of AI. since checkers, you know, at one time somebody said that if chess can be played by a computer, then that will be AI. Well, chess got played by a computer and you, and I certainly don't think of chess. As AI do we, so it's kind of a moving target, but again, we go back to the definition of simulating any intellectual task.

[00:06:23] There is sort of a level to which I can understand where maybe the magic goes away when something is perceived to be pre-programmed. If we're simulating any intellectual task, then you might think of any computer program is AI by that definition. And that does kind of blur the line on the definition of artificial intelligence.

[00:06:43] I think there's sort of a more fuzzy definition, which. Almost layers removed from the programmer, the amount to which the programmer wasn't involved in the decision process. So for example, if I pre-programmed something to play checkers, move for, move for everything that my opponent could throw my way, that doesn't really feel like AI does it.

[00:07:05] It feels like pre-programmed system, but. If I programmed the system to play against the opponent in more of a probabilistic way, I give it a system to bide by the rules of the game. And it can kind of construct its own tree in which to, to try against the opponent. That's maybe one level removed it's I didn't program it with the responses, but I programmed it with the ability to generate its own responses.

[00:07:31] Given the rules of the game. That's a little bit closer to. Kind of in feeling even one layer past, that is what we'll come to in a future episode called deep learning artificial neural networks, which is that in deep reinforcement learning these algorithms, we program it, the capability to learn.

[00:07:52] Anything, any kind of ad hoc representation, you tell it the goal, which is to beat the opponent. And after playing the opponent multiple times, it learns how the game works. So it actually learns the rules of the game. It learns how to play the game and it learns what are effective strategies and playing against the.

[00:08:09] So I programmed it with the algorithm, but I have no idea what's going on inside of that little mind of it's kind of a black box. In fact, neural networks are often called black box approach, and that feels a lot more like artificial intelligence does it. So there's sort of this hard definition of simulating any intellectual task.

[00:08:26] And there's also this soft definition of how far removed from the programmer is the ability of this robot to simulate these intellectual tasks. And there's also, the difference between what's called weak AI and strong AI or AGI or artificial general intelligence. So weak AI is the ability to do a specific task such as playing.

[00:08:49] We don't consider chess to be a conscious being right. We consider it good at chess, an algorithm that can play chess can play chess, but it can't drive a car. So a weak AI is an artificial intelligent agent that can perform one particular task and maybe perform it. And a strong AI is it's something we haven't invented yet.

[00:09:11] It's a theoretical concept of theoretical algorithm that could perform well at any challenge that we give to it. So strong AI would be able to apply itself to all of the applications that I've listed. Autonomous vehicles, medical diagnosis, creative art, proving, mathematical theorems plaintiffs. We also.

[00:09:27] Artificial general intelligence or AGI, and that's sort of the lofty end goal, the last boss of artificial intelligence for those in the field. That's the goal that we all want to achieve. Okay. So that's artificial intelligence simulating any intellectual. What is machine learning? So, like I said, it's a subfield of artificial intelligence.

[00:09:50] It is potentially the most interesting sub field of artificial intelligence. Let's just define it real quick. The kind of the way that machine learning works is kind of this three step process. You have a pattern or a model, the way something is represented a pattern, and then you make a prediction.

[00:10:09] And then you update your pattern based on whether or not your prediction was correct. And that's the learning process. So machine learning goes, pattern predict. Learn. And so you store you, so it's all basically just pattern recognition. That's all machine learning is just boiled down to pattern recognition.

[00:10:27] So again, compared to artificial intelligence is a subfield of artificial intelligence, but it's sort of in my mind, the most interesting and essential subfield of artificial intelligence, because it is fast subsuming. The other sub-fields of artificial intelligence. So for example, let's look at search and planning, a reinforcement learning algorithms, such as a deep Q network is typically involved these days in searching and planning, reason and knowledge, representation, an algorithm put out by Google deep mind or more of a framework or an architecture put out by Google deep mind, that's called a differentiable computer can basically perform reasoning and knowledge representation in the same.

[00:11:08] Prior dedicated algorithms would perception vision previously had, of course you have to have the robotic eyes to take the percepts in the first place. But computing on the information that comes in through the eyes is now almost completely the job of deep learning by way of something called a convolutional neural networks.

[00:11:28] So. That subfield of computer vision has almost completely been subsumed by machine learning, natural language processing. Likewise, where previously there were dedicated algorithms for natural language processing, named entity recognition and all these things. Now we simply have recurrent neural networks and they're very effective at performing the task.

[00:11:48] So machine learning is subsuming the other fields of artificial intelligence. Another reason I kind of want to sell machine learning on you as. Potentially more interesting subfield of artificial intelligence then trying to take on the artificial intelligence hole is that machine learning is a good starter field for people who are getting involved in this space.

[00:12:08] So artificial intelligence is a very broad. And typically, if you're involved in artificial intelligence at a professional level, you are coming from a PhD, a lot to know, and work in the field often involves academic work. You're a professor, or you're doing some stuff at a university machine. Learning is applicable in industry in a way that broad artificial intelligence is not a lot of companies are integrating machine learning into their stack and it's becoming more and more common these days.

[00:12:38] In fact, getting a job in machine learning. Typically only requires a master's in computer science or machine learning or statistics or data science, or one of these fields again, where maybe getting a job in artificial intelligence would require a PhD. Additionally, more and more as these jobs. Prevalent.

[00:12:57] And as machine learning is really picking up an industry. I think machine learning is becoming more accessible to people even without higher degrees, even maybe without a master's, maybe just a bachelor's. And I'm really crossing my fingers that even self-taught machine learning engineers can start to get jobs in the near future.

[00:13:15] And that's the whole goal of my podcast here is to help people start to learn this on their own. And if they don't already have a machine learning. So that's the difference between artificial intelligence and machine learning? let me talk about one more difference. This is a little bit less of a hard difference, and this is I call it the conversational difference.

[00:13:32] It's how you use artificial intelligence versus machine learning. Artificial intelligence is more colloquial. In conversation, whereas machine learning is a little bit more professional. So even if you are a machine learning developer and you're talking to the media or the press or friends or family, you might actually use the term artificial intelligence.

[00:13:50] So you'll see a lot of things in the, in hacker news or tech crunch or any of these things saying like artificial intelligence is being used to work on your taxes or something like this. When the only algorithms being used are machine learning algorithms. While they're talking to the general public. If you're publishing a paper, or if you're talking to your colleagues or if you're releasing a module on Github and you're trying to impress somebody professionally, you'll typically use machine learning.

[00:14:14] If in fact it's machine learning that you're developing in. So there's that little colloquial twists to the difference between artificial intelligence and machine. So that's the difference between artificial intelligence and machine learning? Again, AI is a broader field. ML is a subfield. The ML is kind of is essential AI it's in the more, one of the more interesting sub-fields of AI.

[00:14:36] Now I want to talk about the relationship between ML and statistics and data science. So statistics is a branch of mathematics that deals with probability and inference, just deals with a lot of numbers that deals with data and the types of equations that you learn from your statistics textbooks are the same types of equations that you're going to be using in machine learning.

[00:14:56] In fact, machine learning is statistics have such strong overlap. It's almost as if machine learning. Applied statistics. So statistics as a field of mathematics is probably the most important field of mathematics for you to learn or alternatively, what a lot of people are doing these days is they're learning statistics by way of machine learning effectively.

[00:15:18] Like I said, they're using the same equations. You're kind of mirroring learning one for the other. Now data science. Is the field of computer science that is sort of governed by statistics. So take statistics on the theoretical side, theoretical mathematics apply that in computers and you have data science.

[00:15:39] So data science is another field that has inside of it as a sub field machine learning. So this is a little bit kind of weird. So we have artificial intelligence, a subfield of AI is machine learning, and then we have data science. Uh, subfield is machine learning. Well, where does machine learning belong?

[00:15:59] So you can almost say that let's make a Venn diagram out of it. Let's make artificial intelligence on the left data science on the right and machine learning, connecting the two with a lot of overlap in both spaces. Data science uses statistics and data and computer science in a way that isn't necessarily machine learning for every application.

[00:16:20] So for example, data science can include data mining, which is simply scraping information off the web from Excel spreadsheets or databases or web pages and pulling useful information. Or data analysis. So for example, coming up with charts and graphs so that a data analyst can consume that information to make business decisions, but the sub field that we're interested in data sciences, machine learning, which is taking data, forming patterns out of that data in order that we can make predictions and learning from future experiences.

[00:16:52] So the data scientists can say that they own the machine learning engineers, because machine learning works off of data and the artificial intelligence people can say that they own machine learning because it's learning. So there's a lot in common. There's a lot of overlap. It's a subfield of both spaces now of interest.

[00:17:11] If you wanted to go to school today to become an expert. In one thing, you can choose artificial intelligence, data science, or machine learning. It's likely that the degree you're going to get maybe a master's in either data science or machine learning. If you went with the data science. A master's of data science.

[00:17:28] That would mean that you're working with data across the spectrum, consuming data in the data, mining space, analyzing charts and graphs and the data analysis side and making predictions with machine learning. If you've got a masters in machine learning, you would be specifically honing in on that one vertical.

[00:17:44] And that would be my personal recommendation. If I were to go back to school for a master's and I'm actually thinking about it. I will probably pick machine learning specifically. If you went back to school for artificial intelligence, you're in it for the long haul artificial intelligence is a much broader field with a lot more reach.

[00:18:00] You're typically going to be doing a PhD if you're interested in that space. Okay. So we've covered the definition of artificial intelligence. The definition of machine learning. And now finally, let's go into the history of artificial intelligence. I'm going to recommend you some really good resources that I've picked up from the, from around the web, some common recommendations by people who are looking for good history information on artificial.

[00:18:26] So, artificial intelligence goes way, way back, way back, further than you imagine, starting with Greek mythology and then, you know, coming out in Jewish mythology with Gollums and this is actually a very interesting point to me that artificial intelligence has sort of been conceived of in the Dawn of humanity.

[00:18:44] It's almost like it's part of it was. Our quest. And we're going to get back to that actually in the next episode, which is artificial intelligence inspiration, but we'll try to inspire you around artificial intelligence and machine learning right now. Just keep that in mind. We've been thinking about artificial intelligence since at least Greek mythology, the first.

[00:19:02] Attempt at actually implementing an automaton. I think this guy's name is Raman Lowell in the 13th century, Leonardo DaVinci was working on what he made, some walking animals, automata, Descartes, and , you know, they had a lot of kind of philosophical musings and on consciousness and Libnis on co-created calculus stuff that was used in the development of AI algorithms and mathematics.

[00:19:26] And both of them were thinking about AI. So this theory about AI has been around for a very long time. The real nitty gritty stuff kind of started happening around the 17 hundreds in the 18 hundreds, the period of sort of statistics and mathematical decision-making one of the first, most important figures as Thomas Bayes.

[00:19:43] He worked on reasoning about the probability of events. So Thomas Bayes reasoning about the probability of events. Remember that name? He's going to come up again. multiple times in the future Bayesian inference. Is very important, fundamental component of machine learning. So he's a very big figure.

[00:20:01] George bull, who was involved in logical reasoning and binary algebra Gotlob Frege with propositional logic. So these were components in the development of computers in general, but also in the development of machine learning. Charles Babbage and ADA, Byron slash love Lovelace in 1832 designed the analytical. Which is a programmable calculating machine.

[00:20:22] and then it was in 1936 that we got the universal Turing machine. And I think that a lot of people consider that kind of a kickoff point for computers, Alan Turing designed the con the concept of a programmable computer,with his universal turing machine. It also just so happens that Alan turning was very interested in AI.

[00:20:41] He talked about, he has an article called a computing machinery and intelligence. So he was thinking about AI pretty early on as well. 1946, John Von Neumann uses universal Turing machine and the development of his universal computing machine. if I'm not mistaken, I believe the universal Turing machine was the theoretical and the universal computing machine.

[00:21:00] He actually made a computer. I think John, Von Neuman made the architecture for the first kind of. Programmable computer. And now we finally start to get into the actual machine learning stuff, machine learning and artificial intelligence in 1943, Warren McCulloch and Walter Pitts, they kind of built the computer representation of a neuron that was later refined by Frank Rosenblatt to create the perceptron

[00:21:23] and that word, the perceptron will come back, come up later. That's the first artificial neuron. And of course you stack those in an artificial neuron by way of what's called a multilayer perceptron and you've got an artificial neural network and that is deep learning. That's the fun stuff. So McCulloch and Pitts and.

[00:21:43] Three very important figures. It wasn't until 1956, that the word artificial intelligence was coined by John McCarthy at the Dartmouth workshop. So dark John McCarthy, Marvin Minsky, Arthur, Samuel Oliver, Selfridge, Ray Solemonof, Alan Newell and Herbert Simon. They all came together at Dartmouth into, at this workshop in 1956.

[00:22:06] And their goal was to simulate all aspects of intelligence. End quote, and that is the definition of artificial intelligence at the beginning at this podcast. So these guys defined AI, they created a field of it, and then they set off working. So at the workshop, it was kind of like a hackathon, like a multi-day hackathon.

[00:22:24] They just cracked at it. Newell and Simon created heuristics, sort of the branch of heuristics in machine learning created this thing called the general problem solver. Okay. here we see the. Computer vision, natural language processing, shakey the robot. So this is between the 1950s and the 1970s. So they were working a little bit on this at the actual Dartmouth workshop, but then they all took their projects home to their own universities and they continued cracking at

[00:22:48] these things we call this sort of the golden era of artificial intelligence is when it was like an explosion of interest and research and joy and light in the field fight. Feigenbaum creates expert systems. This is also sort of the creation of what we call. Good old fashioned AI because later you'll see, we kind of switched gears on the way we do AI in today's generation.

[00:23:11] Good old fashioned AI, or GOFAI G O F a. I uses an approach called symbolism. These are logic based approaches, knowledge based expert systems, basically where the knowledge. And the logic is kind of hard-coded into the system. It's a little bit, it's a little bit like that once and twice removed analogy I used back when playing checkers a little bit less magical maybe than the connectionism approach of neural networks.

[00:23:35] but some of the experts, including Marvin Minsky during this time took the side of GOFAI of symbolism. And they said that the connectionism approach of artificial neural networks wouldn't hold it had some problems. So this was the golden era, the fifties and the. The fifties to the seventies, the golden era of an explosion of research and ideas and discoveries and developments by some of the most important and influential names in the history of artificial intelligence that you'll read in any book.

[00:24:05] But there was also a little bit of adversity, between some of the players. And like I said, so, so connectionism began to be criticized. Due to something. What was called calm a combinitorial explosion. Basically neural networks were too hard, computationally, too hard on the computer to be effective at generalizing solutions.

[00:24:27] Going forward on the heel of that in the 1970s came this report by James Lighthill called the Lighthill report, and this did vast damage to the field of artificial intelligence. So, like I said, this was between the fifties and seventies when this golden era was ensuing in artificial intelligence, when the world was just vibrant and excited about AI and in that excitement, DARPA, you know, the military defense and lots of companies invested into these guys, these major players and created companies around these technologies, there was a lot of hype, a lot of excitement and under delivery.

[00:25:05] It was almost like a Silicon valley. Bubble busts. It was almost like they said, we can do anything in the whole universe because we're simulating intelligence. Anything you could imagine intellectually, we can simulate that. But in fact, of course it's a little bit more difficult than that we're getting closer every day, but they under-delivered.

[00:25:23] In too long of a time. And so people started cutting funds and cutting grants and cutting contracts with contractors. And a lot of that was due to this Lighthill report, which was basically a report on all these kind of negative aspects saying, yes indeed, these guys are biting off more than they can chew.

[00:25:42] And they're under-delivering. So that created what we call the AI winter. AI went underground. And very few people were funding it anymore. The AI winter lasted from about the seventies until the nineties, and it started to make the comeback. And the reason it made a come back was that AI finally started to have some practical applications.

[00:26:02] I'm sure it was kind of these diehards that were hiding in the cave. They knew that it would, that it had real application in industry. And so they finally started making some practical use of AI without some lofty promises. So for example, advertising. And recommender engines, which are two of the most commonly used applications of artificial intelligence in the modern era.

[00:26:23] The other thing is that the computers got better. So remember that one of the reasons for the AI winter under delivery was due to this combinitorial explosion that these generalizations generalizing algorithms could not perform on the computers of that modern time, but they could perform on the computers 20 years later, 30 years.

[00:26:44] It was the nineties and the two thousands that AI really started to pick up steam again. And finally, the last piece of the puzzle was data. One thing that you're going to find that I'm going to teach you in later episodes is that the accuracy of your machine learning algorithms improve the more data.

[00:27:00] And with the internet becoming so popular and data becoming so prevalent all over the internet that we could just scrape web pages and there was Excel spreadsheets and databases everywhere of this and that these machine learning algorithms had basically just a gold mine of information to work with.

[00:27:15] This is the era of what's called big data. Now you can work with all the data at your fingertips, as you can imagine. Big. So AI finally made a comeback. Finally had this AI spring after the AI winter. Another reason I think that AI made a come back, which I don't hear touted a lot was actually optimizations to the algorithms.

[00:27:33] I know that they say that our computers got really fast, so the computation, got more efficient, but so did the algorithms. So for example, in 2006, Geoffrey Hinton optimize the backpropagation algorithm, which made artificial neural networks substantially more tractable and put connectionism back on the map, in effect

[00:27:52] I believe it was that this sort of solidified connectionism as a really powerful, commonly used technique going forward. And that go find symbolism started to go out of Vogue. Finally, we have the modern. 2000 2017. Currently Bloomberg says that 2015 was sort of a Whopper for the AI industry. And I don't really know why.

[00:28:14] I think maybe what happened is just, just that this graph that's constantly be on the rise since the nineties has just finally hit a peak that it's become really popular in the modern era. Now, almost any technology company is adopting machine learning and artificial intelligence. They're hiring machine learning, engineers and data.

[00:28:30] scientists like never before. So we're in an explosion of AI. In fact, there's a little bit of concern that it's going to become another bubble bust another AI winter, but there's a lot of people who say that that probably won't happen. That we're actually, we're really doing well with the algorithms and the data.

[00:28:45] The algorithms are very precise. Do the amount of data. We have the computing machines. we can scale these algorithms. Horizontally across an AWS cluster and all these things. So we're in a very, very good time for machine learning. Very interesting and good time to be alive and see what's happening.

[00:29:01] Now. There's one company that I want to draw attention to, and this'll be my final point on the history of artificial intelligence. The company's name is DeepMind and DeepMind was acquired by Google. I believe in 2014, DeepMind at first was kind of. Playing games. it was an artificial intelligence system using deep learning approaches, like deep Q networks in order to play old classic games like pong, and then eventually old console games and more recently modern console games like from PlayStation and such, but Google saw potential in the types of things that they were doing with deep learning in reinforcement learning specifically, and they acquired.

[00:29:36] And DeepMind has been putting out a lot. They have just been demolishing the field of machine learning and artificial intelligence. They're probably the most present figure in the news of artificial intelligence today. They put out papers all the time, making big splashes in research and developments, something I mentioned previously called a differentiable computer, which brought the sub field of knowledge representation.

[00:30:01] And. Into the domain of machine learning. For example, deep mind is something to keep very close eye on. They're doing some really interesting work these days. Okay. So that's a history of artificial intelligence. So we covered, what is AI a definition? What is machine learning compared to AI was machine learning compared to data science compared to statistics.

[00:30:22] Why is ML the sort of essential subfield of AI? And what is the history of AI in brief, if you're interested in the history of AI and the definition of AI, I'm going to provide some resources. there's one book that's commonly recommended and I'll point that out in the show notes. So go to the show notes, O C D E V E L, OCDevel.com And this will be episode two and get those links if you're interested in the history of machine learning. So in the next episode, I'm going to try to, I hope inspire you to be interested in the field of AI and in specifically in machines.

[00:30:58] I think that this episode was probably rather boring. The next episode of all the episodes I have planned so far, the next episode, I think will be the most fun episode. It's going to be inspiration around the field of AI. We're going to talk about the singularity consciousness, automate automation of the entire industry, some really philosophical and crazy stuff.

[00:31:20] So I hope to see you then.

